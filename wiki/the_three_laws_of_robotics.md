---
layout: page
title: The Three Laws Of Robotics
date: 2004-11-16 16:17:54
---
<p>The Three Laws Of Robotics were envisioned by Isaac Asimov<a class="wiki wikinew for-review" title="Create page: Isaac Asimov">?</a>.
<br/>They were founding principles of robot Ai designed to protect humans, and the robots themselves.
</p>
<ul><li>The First Law is that a robot cannot through action or inaction harm or allow to come to harm any human being.
</li><li>The second law is that a robot must follow orders given to it by a human, except where this contradicts the first law.
</li><li>The third law is that a robot must aim to preserve its own existance, except where this conflicts with the first or the second law.
</li></ul><p>
<br/>These laws were built into the very equations and circuitry that the AI ran upon - so in most cases the AI had no way to circumvent them.
</p>
<p>While being a great founding principle - they were not infallible.
<br/>There is one story where a robot must choose between a human holding a gun and a human the gun was aiming at.  If the robot didnt act - the other human would surely die - so it must harm the human with the gun.
</p>
<p>Another very famous tale is the Bicentennial Man<a class="wiki wikinew for-review" title="Create page: Bicentennial Man">?</a> where a robot is ordered by humans to take itself apart.
<br/>Anyone interested in the psychological and other aspects of the interplay of these laws and humans should read I Robot, Robot Visions<a class="wiki wikinew for-review" title="Create page: Robot Visions">?</a>, Robot Dreams<a class="wiki wikinew for-review" title="Create page: Robot Dreams">?</a> and other such works by Isaac Asimov<a class="wiki wikinew for-review" title="Create page: Isaac Asimov">?</a>.
</p>
