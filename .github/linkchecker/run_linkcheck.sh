#!/bin/bash
set -e

# OrionRobots Link Checker Script
echo "ðŸ”— Starting OrionRobots Link Checker..."

SITE_URL="${1:-http://http_serve}"
OUTPUT_DIR="${2:-/linkchecker}"
MODE="${3:-normal}"  # normal, quick, or nightly
REPORT_FILE="$OUTPUT_DIR/link_check_report.html"

echo "ðŸ“ Checking site: $SITE_URL"
echo "ðŸ“ Output directory: $OUTPUT_DIR"
echo "ðŸ”§ Mode: $MODE"

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# Wait for the site to be available
echo "â³ Waiting for site to be available..."
timeout 60 bash -c 'until curl -s "$0" > /dev/null; do sleep 2; done' "$SITE_URL" || {
    echo "âŒ Site not available at $SITE_URL"
    exit 1
}

echo "âœ… Site is available, starting link check..."

# Always use the main config, override with CLI args for quick/nightly
CONFIG_FILE="/linkchecker/linkchecker.conf"
LINKCHECKER_CMD="linkchecker --config=$CONFIG_FILE --output=csv --file-output=csv/linkchecker/output.csv"

if [ "$MODE" = "quick" ]; then
    echo "âš¡ Running in quick mode (2min max, internal links only)..."
    LINKCHECKER_CMD="$LINKCHECKER_CMD \
        --recursion-level=1 \
        --check-extern=0 \
        --max-requests-per-second=20 \
        --timeout=5 \
        --maxrunseconds=120 \
        --verbose=0 \
        --warnings=0 \
        --threads=4"
elif [ "$MODE" = "nightly" ]; then
    echo "ðŸŒ™ Running nightly mode (comprehensive, no time limit)..."
    LINKCHECKER_CMD="$LINKCHECKER_CMD \
        --recursion-level=10 \
        --check-extern=1 \
        --max-requests-per-second=5 \
        --timeout=30 \
        --verbose=1 \
        --warnings=1 \
        --threads=4"
else
    echo "ðŸ” Running normal mode (2min max, limited external checks)..."
    LINKCHECKER_CMD="$LINKCHECKER_CMD \
        --recursion-level=2 \
        --check-extern=1 \
        --max-requests-per-second=10 \
        --timeout=10 \
        --maxrunseconds=120 \
        --verbose=1 \
        --warnings=1 \
        --threads=4"
fi

# Run linkchecker
$LINKCHECKER_CMD "$SITE_URL" || true  # Don't fail on broken links

echo "ðŸ”„ Processing results..."

# Generate HTML report
cd /linkchecker
python3 filter_csv.py output.csv > "$REPORT_FILE"

echo "ðŸ“Š Link check complete!"
echo "ðŸ“„ Report generated: $REPORT_FILE"

# Show summary
if [ -f "output.csv" ]; then
    total_lines=$(wc -l < output.csv)
    if [ "$total_lines" -gt 1 ]; then
        broken_count=$((total_lines - 1))  # Subtract header line
        echo "âŒ Found $broken_count broken links"
        # Copy CSV to output directory for analysis
        cp output.csv "$OUTPUT_DIR/"
    else
        echo "âœ… No broken links found!"
    fi
else
    echo "âš ï¸ No output CSV found"
fi